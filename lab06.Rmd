---
title: "Lab 06"
author: ''
output:
  html_document: default
  html_notebook: default
---

The format of this lab follows the same format as the previous
ones. Your goal is to predict the value of the third column
(which will be missing on the test set) using the techniques
we have learned so far.

*Additionally*: For this lab, fit at least one model using the
matrix formulation we saw today with `lm.fit`. I also encourage
you to figure out a way to use the latitude and longitude
variables, though this is not a requirement.

# Set up

Read in the following libraries and to load the diamonds dataset:

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(viridis)

housing <- read_csv("~/files/ml_data_full/ca_pa_house_price.csv")
```

Notice that the test set here is not a random subset of the data but
has very different properties that than the other variables.

# Lab 06

## Training and Testing Split

Hopefully you noticed that the data are split into training and
testing in an interesting way. Namely, the test set exists only
for houses in Pennsylvania and the training/validation set is
only from California. (You don't need the **ggmap** function
to see this, but replacing `qplot` with `qmplot` gives a nice
map of the data):

```{r, message = FALSE}
library(ggmap)
qmplot(longitude, latitude, data = housing, color = train_id)
```

Of course, our model will perform very differently in these two places
if we use longitude and latitude. Also, the scale of the housing prices
is different in California and Pennsylvania. Therefore I have used the
gain metric instead of the RMSE. To illustrate the gain, I've loaded in
the full dataset (with non-missing responses on the test set). Lets fit
a simple model to the data to illustrate:

```{r}
model <- lm(median_house_value ~ median_rooms + owners,
            data = housing,
            subset = (train_id == "train"))
housing$price_pred <- predict(model, newdata = housing)
```

The RMSE is very different on the test set because housing prices are
significantly lower in Pennslyvania compared to California:

```{r}
sqrt(tapply((housing$price_pred - housing$median_house_value)^2, housing$train_id, mean))
```

## Gain Metric

One way to account for this difference in our data is to use a different
metric to test how good our predictions are. Here, I'll order all of the
predictions from lowest to highest, and plot the cumulative proportion of
the response variable that has been captured by a given proportion of the
data. I have loaded the full dataset (with the full test set) to illustrate
the effect here:

```{r}
prd <- housing$price_pred[housing$train_id == "train"]
val <- housing$median_house_value[housing$train_id == "train"]
val <- val[order(prd, decreasing = TRUE)]
qplot(seq_along(val) / length(val), cumsum(val) / sum(val), geom = "line") +
  geom_abline(intercept = 0, slope = 1, color = "orange") +
  xlab("Proportion of Observations") + ylab("Proportion of Response")
```

Generally, a better estimator will have a larger value under the curve.
The perfect score would be 1, and is usually impossible to achieve. A
value of 0.5 corresponds to random guessing. Here, we have a value
of just over 0.6:

```{r}
gain <- sum(cumsum(val) / sum(val) / length(val))
gain
```

## Using Matrices

As I asked you to do, here we will fit a model using raw matrices. I will
use the median rooms and owners variables as well as the latitude and longitude
variables.

```{r}
X <- as.matrix(select(housing, median_rooms, owners,
                      latitude, longitude))
X <- cbind(1, X)

X_train <- X[housing$train_id == "train",]
X_valid <- X[housing$train_id == "valid",]
X_test  <- X[housing$train_id == "test",]
y_train <- housing$median_house_value[housing$train_id == "train"]
y_valid <- housing$median_house_value[housing$train_id == "valid"]
y_test <- housing$median_house_value[housing$train_id == "test"]

beta <- solve(t(X_train) %*% X_train, t(X_train) %*% y_train)
beta

housing$price_pred <- X %*% beta
```

The gain here is not very good because the latitude and longitude
variable terms do not translate to Pennsylvania:

```{r}
prd <- housing$price_pred[housing$train_id == "test"]
val <- housing$median_house_value[housing$train_id == "test"]
val <- val[order(prd, decreasing = TRUE)]
gain <- sum(cumsum(val) / sum(val) / length(val))
gain
```

Of course, the RMSE is much worse:

```{r}
sqrt(tapply((housing$price_pred - housing$median_house_value)^2, housing$train_id, mean))
```

We can fix this by only applying the terms that do not include spatial
information:

```{r}
housing$price_pred <- X[,1:3] %*% beta[1:3]
```

The gain is not virtually the same as before:

```{r}
prd <- housing$price_pred[housing$train_id == "test"]
val <- housing$median_house_value[housing$train_id == "test"]
val <- val[order(prd, decreasing = TRUE)]
gain <- sum(cumsum(val) / sum(val) / length(val))
gain
```

## Fitting to residuals

Another way to incorporate the spatial component into the model is
to fit a spatial only model to the training data and compute the
residuals:

```{r}
model <- lm(median_house_value ~ poly(longitude, latitude, degree = 3),
            data = housing,
            subset = (train_id == "train"))
housing$residual <- housing$median_house_value - predict(model, newdata = housing)
```

We then fit a non-spatial model to the residuals and use this model
to predict the housing values in Pennsylvania:

```{r}
model <- lm(residual ~ median_rooms + owners,
            data = housing,
            subset = (train_id == "train"))
housing$price_pred <- predict(model, newdata = housing)
prd <- housing$price_pred[housing$train_id == "test"]
val <- housing$median_house_value[housing$train_id == "test"]
val <- val[order(prd, decreasing = TRUE)]
gain <- sum(cumsum(val) / sum(val) / length(val))
gain
```

Again, this did not improve much but shows another way of achieving
a very similar gain.

# Submission

The code below assumes that you have added a prediction named
`price_pred` to every row of the dataset.

```{r}
submit <- select(housing, obs_id, price_pred)
write_csv(submit, "class06_submit.csv")
```

Now, upload this file (ends with ".Rmd"), the HTML output
(ends with ".nb.html" or ".html"), and the csv file to
GitHub.
